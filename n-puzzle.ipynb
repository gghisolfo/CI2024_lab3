{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Copyright **`(c)`** 2024 Giovanni Squillero `<giovanni.squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free under certain conditions — see the [`license`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from heapq import heappush, heappop\n",
    "from collections import namedtuple\n",
    "from typing import List\n",
    "import heapq\n",
    "import heapq\n",
    "from typing import List, Tuple, Callable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Action type\n",
    "Action = namedtuple('Action', ['pos1', 'pos2'])\n",
    "\n",
    "# Define puzzle dimension\n",
    "PUZZLE_DIM = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def available_actions(state: np.ndarray) -> List[Action]:\n",
    "    x, y = [int(_[0]) for _ in np.where(state == 0)]\n",
    "    actions = []\n",
    "    if x > 0:\n",
    "        actions.append(Action((x, y), (x - 1, y)))\n",
    "    if x < PUZZLE_DIM - 1:\n",
    "        actions.append(Action((x, y), (x + 1, y)))\n",
    "    if y > 0:\n",
    "        actions.append(Action((x, y), (x, y - 1)))\n",
    "    if y < PUZZLE_DIM - 1:\n",
    "        actions.append(Action((x, y), (x, y + 1)))\n",
    "    return actions\n",
    "\n",
    "\"\"\"Apply the action to the state.\"\"\"\n",
    "def do_action(state: np.ndarray, action: Action) -> np.ndarray:\n",
    "    new_state = state.copy()\n",
    "    new_state[action.pos1], new_state[action.pos2] = new_state[action.pos2], new_state[action.pos1]\n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Calculate the distance of Manhattan between the current state and the final state.\"\"\"\n",
    "def manhattan_distance(state: np.ndarray, goal: np.ndarray) -> int:\n",
    "    distance = 0\n",
    "    for num in range(1, PUZZLE_DIM**2):  # ignore 0 (the empty space)\n",
    "        x1, y1 = np.where(state == num)\n",
    "        x2, y2 = np.where(goal == num)\n",
    "        distance += abs(x1[0] - x2[0]) + abs(y1[0] - y2[0])\n",
    "    return distance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Reconstruct the path__\n",
    "\n",
    "*Parameters*:\n",
    "- cameFrom (dict): Map of state to its predecessor state.\n",
    "- current (Tuple[int]): Current state (goal state tuple).\n",
    "- shape (Tuple[int]): Shape of the original puzzle.\n",
    "\n",
    "*Returns*:\n",
    "- List[np.ndarray]: Reconstructed path from start to goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Reconstruct the path from start to goal using the cameFrom dictionary.'''\n",
    "def reconstruct_path(cameFrom: dict, current: Tuple[int], shape: Tuple[int]) -> List[np.ndarray]:\n",
    "    path = []\n",
    "    while current in cameFrom:\n",
    "        current_array = np.array(current).reshape(shape)\n",
    "        path.append(current_array)\n",
    "        current = cameFrom[current]\n",
    "    path.reverse()  # Reverse to get the path from start to goal\n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve the puzzle using A* with explicit gScore and fScore\n",
    "__Parameters__:\n",
    "- start_state (np.ndarray): The starting state of the puzzle.\n",
    "- goal_state (np.ndarray): The goal state of the puzzle.\n",
    "- heuristic_func (Callable): A function to calculate the heuristic cost.\n",
    "\n",
    "__Returns__:\n",
    "- List[np.ndarray]: The sequence of states leading to the solution or None if no solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Previous attempts**\n",
    "-  `tentative_gScore = gScore[current_state_tuple] + 1  # Assuming uniform cost of 1 for moves `\n",
    "- `tentative_gScore = gScore[current_state_tuple] + 0.01  # Assuming uniform cost of 1 for moves`\n",
    "- `fScore[neighbor_tuple] = tentative_gScore + 1*heuristic_func(neighbor, goal_state)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f(n) = g(n) + h(n)\n",
    "#g is the actual cost\n",
    "#h is the estimated cost (heuristic)\n",
    "\n",
    "def a_star_with_scores(start_state: np.ndarray, goal_state: np.ndarray, heuristic_func: Callable[[np.ndarray, np.ndarray], float]) -> List[np.ndarray]:\n",
    "    \n",
    "    # Priority queue (open set)\n",
    "    open_set = []\n",
    "    \n",
    "    # Convert states to tuples for immutability\n",
    "    start_state_tuple = tuple(start_state.flatten())\n",
    "    goal_state_tuple = tuple(goal_state.flatten())\n",
    "    \n",
    "    # Initialize gScore and fScore\n",
    "    gScore = {start_state_tuple: 0}  # Cost from start to this node\n",
    "    fScore = {start_state_tuple: heuristic_func(start_state, goal_state)}  # Estimated total cost\n",
    "    \n",
    "    # Push the start state into the open set with its heuristic value\n",
    "    heapq.heappush(open_set, (fScore[start_state_tuple], start_state_tuple))\n",
    "    \n",
    "    # Dictionary to reconstruct the path\n",
    "    cameFrom = {}\n",
    "\n",
    "    while open_set:\n",
    "        # Pop the node with the lowest fScore\n",
    "        _, current_state_tuple = heapq.heappop(open_set)\n",
    "        current_state = np.array(current_state_tuple).reshape(start_state.shape)\n",
    "\n",
    "        # Goal test\n",
    "        if np.array_equal(current_state, goal_state):\n",
    "            return reconstruct_path(cameFrom, current_state_tuple, start_state.shape)\n",
    "\n",
    "        # Generate successors (neighbors)\n",
    "        for action in available_actions(current_state):  # Define available_actions\n",
    "            neighbor = do_action(current_state, action)  # Define do_action\n",
    "            neighbor_tuple = tuple(neighbor.flatten())\n",
    "\n",
    "            # Tentative gScore for the neighbor\n",
    "            tentative_gScore = gScore[current_state_tuple] + 0.01*heuristic_func(neighbor, goal_state)\n",
    "\n",
    "\n",
    "            # If this path is better than any previous path to the neighbor\n",
    "            if tentative_gScore < gScore.get(neighbor_tuple, float('inf')):\n",
    "                # Record this path as the best so far\n",
    "                cameFrom[neighbor_tuple] = current_state_tuple\n",
    "                gScore[neighbor_tuple] = tentative_gScore\n",
    "                fScore[neighbor_tuple] = tentative_gScore + 1.5*heuristic_func(neighbor, goal_state)\n",
    "\n",
    "                # Add neighbor to the open set if not already there\n",
    "                if neighbor_tuple not in [item[1] for item in open_set]:\n",
    "                    heapq.heappush(open_set, (fScore[neighbor_tuple], neighbor_tuple))\n",
    "\n",
    "    return None  # Return None if no solution is found\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initalization\n",
    "- A solution is always found in fewer than 1000 steps, so 1000 randomized steps are sufficient.\n",
    "\n",
    "**Previous attempts**\n",
    "- ` RANDOMIZE_STEPS = 100_000 ` \n",
    "- `RANDOMIZE_STEPS = 100 `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Randomizing: 100%|██████████| 1000/1000 [00:00<00:00, 90155.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial State:\n",
      "[[ 2 31 15 18  5  6]\n",
      " [33  8 10 23 21  0]\n",
      " [27 34  1  4 28 16]\n",
      " [26  7 13  3 24 12]\n",
      " [ 9 29 32 20 35 11]\n",
      " [22 25 30 19 17 14]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Goal_State = np.array([i for i in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "\n",
    "RANDOMIZE_STEPS = 1000 \n",
    "state = np.array([i for i in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "for r in tqdm(range(RANDOMIZE_STEPS), desc='Randomizing'):\n",
    "    state = do_action(state, choice(available_actions(state)))\n",
    "\n",
    "\n",
    "print(\"Initial State:\")\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[253], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m solution_path \u001b[38;5;241m=\u001b[39m \u001b[43ma_star_with_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mGoal_State\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmanhattan_distance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSolution Steps:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSolution found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(solution_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m moves.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[251], line -1\u001b[0m, in \u001b[0;36ma_star_with_scores\u001b[1;34m(start_state, goal_state, heuristic_func)\u001b[0m\n\u001b[0;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "solution_path = a_star_with_scores(state, Goal_State, manhattan_distance)\n",
    "print(\"\\nSolution Steps:\")\n",
    "print(f\"Solution found in {len(solution_path)} moves.\")\n",
    "# if solution_path:\n",
    "#     print(\"\\nSolution found!\")\n",
    "#     for step, state in enumerate(solution_path):\n",
    "#         print(f\"Step {step}:\")\n",
    "#         print(state)\n",
    "# else:\n",
    "#     print(\"\\nNo solution found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
